{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEOIkMPpNbma7OXqNu2gO6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0f-_IJchrcP","executionInfo":{"status":"ok","timestamp":1740628273514,"user_tz":300,"elapsed":47959,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"83275b5f-7294-416c-e809-09cc17b99838"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.70\n","Recall: 0.78\n","F1 Score: 0.63\n","Accuracy: 0.59\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler, StandardScaler\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml import Pipeline\n","\n","spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()\n","\n","data = [\n","    (30, 0.5, 5, 0.1, 0), (60, 1.2, 20, 0.3, 1), (50, 1.0, 15, 0.2, 0),\n","    (40, 1.5, 30, 0.5, 0), (80, 2.0, 25, 0.4, 1), (55, 1.2, 10, 0.1, 0),\n","    (45, 0.8, 40, 0.2, 0), (90, 2.5, 35, 0.3, 1), (20, 0.5, 50, 0.5, 1),\n","    (35, 0.2, 5, 0.1, 0), (70, 0.1, 10, 0.2, 0), (65, 0.5, 20, 0.1, 1),\n","    (30, 0.3, 15, 0.3, 0), (85, 0.4, 25, 0.4, 1), (75, 0.8, 30, 0.5, 1),\n","    (95, 0.7, 35, 0.2, 0), (100, 1.5, 40, 0.3, 0), (25, 1.8, 45, 0.4, 1),\n","    (15, 1.0, 50, 0.5, 1), (10, 0.9, 5, 0.1, 0),\n","    (50, 0.6, 10, 0.3, 0), (60, 0.4, 20, 0.2, 0), (55, 0.2, 30, 0.3, 1),\n","    (45, 0.3, 40, 0.1, 0), (90, 0.5, 10, 0.4, 1), (95, 0.4, 15, 0.2, 0),\n","    (40, 0.5, 20, 0.3, 1), (30, 0.7, 25, 0.4, 1), (20, 0.3, 30, 0.5, 0),\n","    (10, 0.2, 35, 0.4, 1), (0, 0.1, 5, 0.1, 0), (10, 0.5, 20, 0.2, 1),\n","    (20, 0.6, 15, 0.3, 0), (30, 0.7, 10, 0.1, 1), (40, 0.9, 25, 0.4, 0),\n","    (50, 0.8, 35, 0.5, 1), (40, 0.4, 20, 0.3, 0), (35, 0.5, 30, 0.4, 1),\n","    (30, 0.6, 40, 0.5, 0), (25, 0.7, 15, 0.1, 1), (20, 0.3, 5, 0.2, 0),\n","    (15, 0.2, 10, 0.3, 0), (10, 0.1, 5, 0.1, 1), (5, 0.0, 0, 0.0, 0),\n","    (100, 0.6, 10, 0.2, 0), (95, 0.7, 20, 0.3, 1), (90, 0.8, 15, 0.2, 0),\n","    (85, 0.9, 25, 0.4, 1), (80, 0.8, 30, 0.5, 1), (75, 0.7, 35, 0.4, 0),\n","    (70, 0.6, 40, 0.3, 0), (60, 0.5, 5, 0.1, 0), (50, 0.4, 20, 0.2, 1),\n","    (40, 0.5, 15, 0.3, 0), (30, 0.6, 10, 0.1, 0), (20, 0.2, 25, 0.4, 1),\n","    (10, 0.3, 30, 0.5, 1), (0, 0.1, 5, 0.2, 0), (10, 0.5, 20, 0.3, 0),\n","    (20, 0.6, 15, 0.4, 1), (30, 0.7, 25, 0.5, 1), (40, 0.4, 10, 0.1, 0),\n","    (50, 0.3, 5, 0.2, 0), (60, 0.2, 20, 0.3, 1), (70, 0.5, 15, 0.4, 1)\n","]\n","\n","columns = ['Network Quality: Latency', 'Network Quality: Dropped Calls', 'Internet Usage (GB)', 'Network Quality: Data Drops', 'Churn']\n","df = spark.createDataFrame(data, columns)\n","\n","train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n","\n","assembler = VectorAssembler(\n","    inputCols=['Network Quality: Latency', 'Network Quality: Dropped Calls', 'Internet Usage (GB)', 'Network Quality: Data Drops'],\n","    outputCol=\"features\"\n",")\n","\n","scaler = StandardScaler(\n","    inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True\n",")\n","\n","dt = DecisionTreeClassifier(\n","    featuresCol=\"scaled_features\", labelCol=\"Churn\", maxDepth=5\n",")\n","\n","pipeline = Pipeline(stages=[assembler, scaler, dt])\n","\n","model = pipeline.fit(train_df)\n","\n","predictions = model.transform(test_df)\n","\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n","\n","precision_evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"precisionByLabel\"\n",")\n","recall_evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"recallByLabel\"\n",")\n","f1_evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\"\n",")\n","\n","precision = precision_evaluator.evaluate(predictions)\n","recall = recall_evaluator.evaluate(predictions)\n","f1 = f1_evaluator.evaluate(predictions)\n","\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","accuracy_evaluator = BinaryClassificationEvaluator(\n","    labelCol=\"Churn\", rawPredictionCol=\"prediction\"\n",")\n","accuracy = accuracy_evaluator.evaluate(predictions)\n","print(f'Accuracy: {accuracy:.2f}')\n"]}]}