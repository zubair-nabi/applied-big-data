{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7htiA0zIzrD05tSfP9DP9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install graphframes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSKCkECiyLOG","executionInfo":{"status":"ok","timestamp":1738619381938,"user_tz":300,"elapsed":5553,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"30632cc5-4101-4b7f-8f24-89dc3d36a004"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: graphframes in /usr/local/lib/python3.11/dist-packages (0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphframes) (1.26.4)\n","Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from graphframes) (1.3.7)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zAJFQwuxplr","executionInfo":{"status":"ok","timestamp":1738619971576,"user_tz":300,"elapsed":21436,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"d2b76187-0be8-46ea-a4e9-4ea5f2825634"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"]},{"output_type":"stream","name":"stdout","text":["+---+-------------------+\n","| id|           pagerank|\n","+---+-------------------+\n","|  0|0.38778955828885675|\n","|  1|0.21481090558570037|\n","|  2| 0.3973995361254429|\n","+---+-------------------+\n","\n"]}],"source":["from pyspark.sql import SparkSession, functions as F\n","from graphframes import GraphFrame\n","\n","spark = SparkSession.builder \\\n","    .appName(\"PageRank with GraphFrames\") \\\n","    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.4-spark3.5-s_2.12\") \\\n","    .getOrCreate()\n","\n","vertices = spark.createDataFrame([(0,), (1,), (2,)], [\"id\"])\n","edges = spark.createDataFrame([\n","    (0, 1),\n","    (0, 2),\n","    (1, 2),\n","    (2, 0)\n","], [\"src\", \"dst\"])\n","\n","gf = GraphFrame(vertices, edges)\n","\n","damping_factor = 0.85\n","reset_prob = 1.0 - damping_factor\n","tolerance = 1.0e-6\n","\n","pagerank_results = gf.pageRank(resetProbability=reset_prob, tol=tolerance)\n","\n","pagerank_df = pagerank_results.vertices\n","\n","sum_rank = pagerank_df.agg(F.sum(\"pagerank\").alias(\"total\")).collect()[0][\"total\"]\n","\n","pagerank_df = pagerank_df.withColumn(\"pagerank\", F.col(\"pagerank\") / F.lit(sum_rank))\n","\n","pagerank_df.show()\n"]}]}