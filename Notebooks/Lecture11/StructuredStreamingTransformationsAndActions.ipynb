{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOahpxYFbsBD5+zD+cNzX/z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["The first piece of code starts a socket server in the background and publishes random sensor data on port 9999."],"metadata":{"id":"kWm4l9R-fPDR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MjTyUGkLR98T","executionInfo":{"status":"ok","timestamp":1744328470740,"user_tz":-300,"elapsed":72,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"25784e19-777c-481d-d02f-27df1d3337c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Server started on 127.0.0.1:9999Socket server is running in the background.\n","\n"]}],"source":["import socket\n","import random\n","import json\n","from datetime import datetime\n","import time\n","import threading\n","\n","host = \"127.0.0.1\"\n","port = 9999\n","\n","server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n","server_socket.bind((host, port))\n","server_socket.listen(1)\n","\n","def publish_message(client_socket):\n","    while True:\n","        random_value = round(random.uniform(60.0, 100.0), 2)\n","        quality = \"Good\" if random_value > 70 else \"Fair\"\n","\n","        message = {\n","            \"sensorId\": \"temp-sensor-001\",\n","            \"value\": random_value,\n","            \"quality\": quality,\n","            \"timestamp\": datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ')\n","        }\n","\n","        message_str = json.dumps(message) + \"\\n\"\n","        client_socket.sendall(message_str.encode('utf-8'))\n","        time.sleep(1)\n","\n","def start_socket_server():\n","    print(f\"Server started on {host}:{port}\")\n","    while True:\n","        client_socket, client_address = server_socket.accept()\n","        print(f\"Connection established with {client_address}\")\n","\n","        publish_thread = threading.Thread(target=publish_message, args=(client_socket,))\n","        publish_thread.daemon = True\n","        publish_thread.start()\n","\n","socket_server_thread = threading.Thread(target=start_socket_server)\n","socket_server_thread.daemon = True\n","socket_server_thread.start()\n","\n","print(\"Socket server is running in the background.\")\n"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, from_json\n","from pyspark.sql.types import StringType, StructType, StructField, DoubleType\n","\n","spark = SparkSession.builder \\\n","    .appName(\"SocketStreamExample\") \\\n","    .master(\"local\") \\\n","    .getOrCreate()\n","\n","schema = StructType([\n","    StructField(\"sensorId\", StringType(), True),\n","    StructField(\"value\", DoubleType(), True),\n","    StructField(\"quality\", StringType(), True),\n","    StructField(\"timestamp\", StringType(), True)\n","])\n","\n","streaming_df = spark.readStream \\\n","    .format(\"socket\") \\\n","    .option(\"host\", \"127.0.0.1\") \\\n","    .option(\"port\", 9999)  \\\n","    .load()\n","\n","parsed_df = streaming_df.select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\"))\n","parsed_df = parsed_df.select(\"data.sensorId\", \"data.value\", \"data.quality\", \"data.timestamp\")\n"],"metadata":{"id":"s4NlMziZdtHI","executionInfo":{"status":"ok","timestamp":1744328497538,"user_tz":-300,"elapsed":26787,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def print_stream(streaming_df, output_mode=\"append\"):\n","\n","  def process_batch(df, epoch_id):\n","          df.show()\n","\n","  query = streaming_df.writeStream \\\n","      .foreachBatch(process_batch) \\\n","      .outputMode(output_mode) \\\n","      .start()\n","\n","\n","  try:\n","      query.awaitTermination()\n","  except KeyboardInterrupt:\n","      query.stop()"],"metadata":{"id":"o0iwHaHh8DVY","executionInfo":{"status":"ok","timestamp":1744328497748,"user_tz":-300,"elapsed":44,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print_stream(parsed_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJXjdsBdomXp","executionInfo":{"status":"ok","timestamp":1744328533766,"user_tz":-300,"elapsed":11811,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"51d1bd64-9054-4a43-994d-12609342563c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 33430)\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|92.25|   Good|2025-04-10T23:42:03Z|\n","|temp-sensor-001|94.78|   Good|2025-04-10T23:42:04Z|\n","|temp-sensor-001| 87.0|   Good|2025-04-10T23:42:05Z|\n","|temp-sensor-001|64.35|   Fair|2025-04-10T23:42:06Z|\n","|temp-sensor-001|68.61|   Fair|2025-04-10T23:42:07Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|77.85|   Good|2025-04-10T23:42:08Z|\n","|temp-sensor-001|65.21|   Fair|2025-04-10T23:42:09Z|\n","|temp-sensor-001|73.97|   Good|2025-04-10T23:42:10Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|71.47|   Good|2025-04-10T23:42:11Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|95.03|   Good|2025-04-10T23:42:12Z|\n","+---------------+-----+-------+--------------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","                          ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n","    return self._sock.recv_into(b)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","ERROR:py4j.clientserver:There was an exception while executing the Python Proxy on the Python Side.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 617, in _call_proxy\n","    return_value = getattr(self.pool[obj_id], method)(*params)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/utils.py\", line 120, in call\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/utils.py\", line 117, in call\n","    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)\n","  File \"<ipython-input-3-2e31e43e705e>\", line 4, in process_batch\n","    df.show()\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\", line 947, in show\n","    print(self._show_string(n, truncate, vertical))\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\", line 965, in _show_string\n","    return self._jdf.showString(n, 20, vertical)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n","    return_value = get_return_value(\n","                   ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n","    return f(*a, **kw)\n","           ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n","    raise Py4JJavaError(\n","py4j.protocol.Py4JJavaError: An error occurred while calling o71.showString.\n",": java.lang.InterruptedException\n","\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1343)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n","\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:342)\n","\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:980)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n","\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n","\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n","\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n","\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\n","\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\n","\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\n","\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n","\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n","\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\n","\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\n","\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\n","\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n","\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n","\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n","\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n","\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n","\tat com.sun.proxy.$Proxy30.call(Unknown Source)\n","\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n","\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n","\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n","\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n","\n"]}]},{"cell_type":"code","source":["selected_columns_df = parsed_df.select(\"sensorId\", \"value\")\n","\n","print_stream(selected_columns_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMNTBtCyh9C-","executionInfo":{"status":"ok","timestamp":1744316464235,"user_tz":-300,"elapsed":2943,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"be1985db-4fd9-4dde-a0ab-ed3e64976db6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 44374)\n","+--------+-----+\n","|sensorId|value|\n","+--------+-----+\n","+--------+-----+\n","\n","+---------------+-----+\n","|       sensorId|value|\n","+---------------+-----+\n","|temp-sensor-001|70.78|\n","+---------------+-----+\n","\n","+---------------+-----+\n","|       sensorId|value|\n","+---------------+-----+\n","|temp-sensor-001|70.77|\n","+---------------+-----+\n","\n","+---------------+-----+\n","|       sensorId|value|\n","+---------------+-----+\n","|temp-sensor-001|63.43|\n","+---------------+-----+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","                          ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n","    return self._sock.recv_into(b)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["with_column_df = parsed_df.withColumn(\"value_celsius\", (col(\"value\") - 32) * 5 / 9)\n","\n","print_stream(with_column_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ABBNdSFjPk8","executionInfo":{"status":"ok","timestamp":1744328564511,"user_tz":-300,"elapsed":17763,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"3ae3eac2-1948-442d-c2cf-9f1e3961fad2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 40492)\n","+--------+-----+-------+---------+-------------+\n","|sensorId|value|quality|timestamp|value_celsius|\n","+--------+-----+-------+---------+-------------+\n","+--------+-----+-------+---------+-------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|99.37|   Good|2025-04-10T23:42:27Z|37.42777777777778|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+----------------+\n","|       sensorId|value|quality|           timestamp|   value_celsius|\n","+---------------+-----+-------+--------------------+----------------+\n","|temp-sensor-001|91.29|   Good|2025-04-10T23:42:28Z|32.9388888888889|\n","+---------------+-----+-------+--------------------+----------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|93.75|   Good|2025-04-10T23:42:29Z|34.30555555555556|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001|89.51|   Good|2025-04-10T23:42:30Z|31.950000000000003|\n","+---------------+-----+-------+--------------------+------------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|79.47|   Good|2025-04-10T23:42:31Z|26.37222222222222|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|62.44|   Fair|2025-04-10T23:42:32Z|16.91111111111111|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|99.56|   Good|2025-04-10T23:42:33Z|37.53333333333333|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|98.67|   Good|2025-04-10T23:42:34Z|37.03888888888889|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001|97.89|   Good|2025-04-10T23:42:35Z|36.605555555555554|\n","+---------------+-----+-------+--------------------+------------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001|79.28|   Good|2025-04-10T23:42:36Z|26.266666666666666|\n","+---------------+-----+-------+--------------------+------------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|77.22|   Good|2025-04-10T23:42:37Z|25.12222222222222|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001|74.78|   Good|2025-04-10T23:42:38Z|23.766666666666666|\n","+---------------+-----+-------+--------------------+------------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|95.57|   Good|2025-04-10T23:42:39Z|35.31666666666666|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001|69.04|   Fair|2025-04-10T23:42:40Z|20.577777777777783|\n","+---------------+-----+-------+--------------------+------------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|67.92|   Fair|2025-04-10T23:42:41Z|19.95555555555556|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+-----------------+\n","|       sensorId|value|quality|           timestamp|    value_celsius|\n","+---------------+-----+-------+--------------------+-----------------+\n","|temp-sensor-001|85.77|   Good|2025-04-10T23:42:42Z|29.87222222222222|\n","+---------------+-----+-------+--------------------+-----------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001| 69.9|   Fair|2025-04-10T23:42:43Z|21.055555555555557|\n","+---------------+-----+-------+--------------------+------------------+\n","\n","+---------------+-----+-------+--------------------+------------------+\n","|       sensorId|value|quality|           timestamp|     value_celsius|\n","+---------------+-----+-------+--------------------+------------------+\n","|temp-sensor-001|85.13|   Good|2025-04-10T23:42:44Z|29.516666666666666|\n","+---------------+-----+-------+--------------------+------------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","                          ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n","    return self._sock.recv_into(b)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["filtered_df = parsed_df.filter(col(\"value\") > 70.0)\n","\n","print_stream(filtered_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIY0zc419KFi","executionInfo":{"status":"ok","timestamp":1731462033452,"user_tz":300,"elapsed":13703,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"5f94e7fe-4ced-4d37-f29f-a260310e2e8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 44720)\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|80.95|   Good|2024-11-13T01:40:20Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|95.16|   Good|2024-11-13T01:40:21Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|97.39|   Good|2024-11-13T01:40:22Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|85.33|   Good|2024-11-13T01:40:23Z|\n","+---------------+-----+-------+--------------------+\n","\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001| 87.3|   Good|2024-11-13T01:40:25Z|\n","+---------------+-----+-------+--------------------+\n","\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|96.06|   Good|2024-11-13T01:40:28Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|87.32|   Good|2024-11-13T01:40:29Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|90.37|   Good|2024-11-13T01:40:30Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001| 80.3|   Good|2024-11-13T01:40:31Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|80.82|   Good|2024-11-13T01:40:32Z|\n","+---------------+-----+-------+--------------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n","    return self._sock.recv_into(b)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["aggregated_df = parsed_df.groupBy(\"sensorId\").agg({\"value\": \"avg\"})\n","print_stream(aggregated_df, \"complete\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRHByg5P_Jva","executionInfo":{"status":"ok","timestamp":1731462134445,"user_tz":300,"elapsed":81702,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"bfd28877-8b4c-429b-83ea-105802f72d99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 56934)\n","+--------+----------+\n","|sensorId|avg(value)|\n","+--------+----------+\n","+--------+----------+\n","\n","+---------------+----------+\n","|       sensorId|avg(value)|\n","+---------------+----------+\n","|temp-sensor-001|   81.3376|\n","+---------------+----------+\n","\n","+---------------+-----------------+\n","|       sensorId|       avg(value)|\n","+---------------+-----------------+\n","|temp-sensor-001|81.36638297872341|\n","+---------------+-----------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n","    return self._sock.recv_into(b)\n","KeyboardInterrupt\n","ERROR:py4j.clientserver:There was an exception while executing the Python Proxy on the Python Side.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 617, in _call_proxy\n","    return_value = getattr(self.pool[obj_id], method)(*params)\n","  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py\", line 120, in call\n","    raise e\n","  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py\", line 117, in call\n","    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)\n","  File \"<ipython-input-3-2e31e43e705e>\", line 4, in process_batch\n","    df.show()\n","  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\", line 947, in show\n","    print(self._show_string(n, truncate, vertical))\n","  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\", line 965, in _show_string\n","    return self._jdf.showString(n, 20, vertical)\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n","    return_value = get_return_value(\n","  File \"/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n","    return f(*a, **kw)\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n","    raise Py4JJavaError(\n","py4j.protocol.Py4JJavaError: An error occurred while calling o276.showString.\n",": java.lang.InterruptedException\n","\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1040)\n","\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1345)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n","\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:342)\n","\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:980)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n","\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n","\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n","\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n","\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\n","\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\n","\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\n","\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n","\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n","\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\n","\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\n","\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\n","\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n","\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n","\tat jdk.internal.reflect.GeneratedMethodAccessor37.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n","\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n","\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n","\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n","\tat com.sun.proxy.$Proxy30.call(Unknown Source)\n","\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n","\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n","\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n","\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n","\n"]}]},{"cell_type":"code","source":["sorted_df = aggregated_df.orderBy(col(\"avg(value)\").desc())\n","print_stream(sorted_df, \"complete\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpOqqTWORNlF","executionInfo":{"status":"ok","timestamp":1731430303842,"user_tz":300,"elapsed":65698,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"ebe0a97a-1d39-47c5-8f51-eb93f74e5ffe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 47786)\n","+--------+----------+\n","|sensorId|avg(value)|\n","+--------+----------+\n","+--------+----------+\n","\n","+---------------+-----------------+\n","|       sensorId|       avg(value)|\n","+---------------+-----------------+\n","|temp-sensor-001|82.89699999999998|\n","+---------------+-----------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n","    return self._sock.recv_into(b)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import window\n","\n","windowed_df = parsed_df \\\n","    .groupBy(\"sensorId\", window(col(\"timestamp\"), \"5 seconds\")) \\\n","    .agg({\"value\": \"max\"}) \\\n","    .select(\"sensorId\", \"window.start\", \"window.end\", col(\"max(value)\").alias(\"max_value\"))\n","\n","print_stream(windowed_df, \"complete\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWBZLvRbUahN","executionInfo":{"status":"ok","timestamp":1744316946040,"user_tz":-300,"elapsed":43650,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"be18397c-212c-498d-e510-fdbc64b5e41e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 48854)\n","+--------+-----+---+---------+\n","|sensorId|start|end|max_value|\n","+--------+-----+---+---------+\n","+--------+-----+---+---------+\n","\n","+---------------+-------------------+-------------------+---------+\n","|       sensorId|              start|                end|max_value|\n","+---------------+-------------------+-------------------+---------+\n","|temp-sensor-001|2025-04-10 20:28:40|2025-04-10 20:28:45|    87.12|\n","|temp-sensor-001|2025-04-10 20:28:30|2025-04-10 20:28:35|    98.73|\n","|temp-sensor-001|2025-04-10 20:28:25|2025-04-10 20:28:30|    94.74|\n","|temp-sensor-001|2025-04-10 20:28:35|2025-04-10 20:28:40|    79.14|\n","|temp-sensor-001|2025-04-10 20:28:20|2025-04-10 20:28:25|    85.04|\n","+---------------+-------------------+-------------------+---------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","                          ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n","    return self._sock.recv_into(b)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","ERROR:py4j.clientserver:There was an exception while executing the Python Proxy on the Python Side.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 617, in _call_proxy\n","    return_value = getattr(self.pool[obj_id], method)(*params)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/utils.py\", line 120, in call\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/utils.py\", line 117, in call\n","    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)\n","  File \"<ipython-input-3-2e31e43e705e>\", line 4, in process_batch\n","    df.show()\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\", line 947, in show\n","    print(self._show_string(n, truncate, vertical))\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\", line 965, in _show_string\n","    return self._jdf.showString(n, 20, vertical)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n","    return_value = get_return_value(\n","                   ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n","    return f(*a, **kw)\n","           ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n","    raise Py4JJavaError(\n","py4j.protocol.Py4JJavaError: An error occurred while calling o118.showString.\n",": java.lang.InterruptedException\n","\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1040)\n","\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1345)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n","\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:342)\n","\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:980)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n","\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n","\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\n","\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\n","\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\n","\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\n","\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\n","\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\n","\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n","\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n","\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\n","\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\n","\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\n","\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\n","\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n","\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n","\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n","\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n","\tat com.sun.proxy.$Proxy30.call(Unknown Source)\n","\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n","\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n","\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n","\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n","\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n","\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n","\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n","\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n","\n"]}]},{"cell_type":"code","source":["repartitioned_df = parsed_df.repartition(3)\n","print_stream(repartitioned_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vx2CkBk8WUX9","executionInfo":{"status":"ok","timestamp":1731431340562,"user_tz":300,"elapsed":4762,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"c18f5cae-be92-4e4b-863a-307c625fdd80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Connection established with ('127.0.0.1', 60816)\n","+--------+-----+-------+---------+\n","|sensorId|value|quality|timestamp|\n","+--------+-----+-------+---------+\n","+--------+-----+-------+---------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|93.83|   Good|2024-11-12T17:08:55Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|86.41|   Good|2024-11-12T17:08:56Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|71.83|   Good|2024-11-12T17:08:57Z|\n","+---------------+-----+-------+--------------------+\n","\n","+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|88.49|   Good|2024-11-12T17:08:58Z|\n","+---------------+-----+-------+--------------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:KeyboardInterrupt while sending command.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n","    response = connection.send_command(command)\n","  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n","    answer = smart_decode(self.stream.readline()[:-1])\n","  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n","    return self._sock.recv_into(b)\n","KeyboardInterrupt\n"]},{"output_type":"stream","name":"stdout","text":["+---------------+-----+-------+--------------------+\n","|       sensorId|value|quality|           timestamp|\n","+---------------+-----+-------+--------------------+\n","|temp-sensor-001|61.76|   Fair|2024-11-12T17:08:59Z|\n","+---------------+-----+-------+--------------------+\n","\n"]}]}]}