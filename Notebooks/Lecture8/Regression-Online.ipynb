{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhrUfRiWnHBfxRYNrMGBgW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moyh587iKhQU","executionInfo":{"status":"ok","timestamp":1729599647068,"user_tz":240,"elapsed":1085,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"201c5912-8839-4d69-acb3-4446deb6787d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial RMSE after first 10,000 records: 22557.13\n","RMSE after adding 100 new records: 21409.20\n","RMSE after adding 200 new records: 28436.20\n","RMSE after adding 300 new records: 22059.19\n","RMSE after adding 400 new records: 21883.62\n","RMSE after adding 500 new records: 22779.52\n","RMSE after adding 600 new records: 24104.19\n","RMSE after adding 700 new records: 23584.44\n","RMSE after adding 800 new records: 21138.18\n","RMSE after adding 900 new records: 20786.38\n","RMSE after adding 1000 new records: 25226.12\n","Continuous learning with 100-record updates finished.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n","  return bound(*args, **kwds)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n","  return bound(*args, **kwds)\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","np.random.seed(42)\n","locations = ['Los Angeles, CA', 'San Francisco, CA', 'Austin, TX', 'Miami, FL', 'New York, NY', 'Denver, CO', 'Chicago, IL', 'Seattle, WA', 'Atlanta, GA', 'Boston, MA']\n","conditions = ['Good', 'Excellent', 'Fair']\n","nearby_transport_options = ['Yes', 'No']\n","\n","data = {\n","    'Location': [np.random.choice(locations) for _ in range(11000)],\n","    'Bedrooms': np.random.randint(1, 5, size=11000),\n","    'Bathrooms': np.random.randint(1, 4, size=11000),\n","    'Size_SqFt': np.random.normal(loc=1500, scale=300, size=11000),\n","    'Lot_Size_SqFt': np.random.normal(loc=5000, scale=1000, size=11000),\n","    'Year_Built': np.random.randint(1950, 2024, size=11000),\n","    'Condition': [np.random.choice(conditions) for _ in range(11000)],\n","    'Days_on_Market': np.random.randint(10, 90, size=11000),\n","    'Interest_Rate (%)': np.random.uniform(2.5, 5.0, size=11000),\n","    'Median_Income ($)': np.random.normal(loc=80000, scale=15000, size=11000),\n","    'School_Rating': np.random.randint(5, 10, size=11000),\n","    'Walkability_Score': np.random.randint(50, 100, size=11000),\n","    'Nearby_Transport': [np.random.choice(nearby_transport_options) for _ in range(11000)],\n","}\n","\n","df = pd.DataFrame(data)\n","\n","df['Sale_Price ($)'] = (100000 +\n","                        df['Bedrooms'] * 30000 +\n","                        df['Bathrooms'] * 20000 +\n","                        df['Size_SqFt'] * 200 +\n","                        df['Lot_Size_SqFt'] * 10 +\n","                        df['Median_Income ($)'] * 0.5 +\n","                        np.random.normal(0, 20000, size=11000))\n","\n","df['Location'] = df['Location'].astype('category').cat.codes\n","df['Condition'] = df['Condition'].astype('category').cat.codes\n","df['Nearby_Transport'] = df['Nearby_Transport'].apply(lambda x: 1 if x == 'Yes' else 0)\n","\n","df.drop(columns=['Year_Built'], inplace=True)\n","scaler = StandardScaler()\n","scaled_columns = ['Size_SqFt', 'Lot_Size_SqFt', 'Days_on_Market', 'Interest_Rate (%)', 'Median_Income ($)', 'School_Rating', 'Walkability_Score']\n","df[scaled_columns] = scaler.fit_transform(df[scaled_columns])\n","\n","X = df.drop(columns=['Sale_Price ($)'])\n","y = df['Sale_Price ($)']\n","\n","X_initial_train, X_new_data = X[:10000], X[10000:]\n","y_initial_train, y_new_data = y[:10000], y[10000:]\n","\n","new_data_chunks = np.array_split(X_new_data, 10)\n","new_target_chunks = np.array_split(y_new_data, 10)\n","\n","model = SGDRegressor(max_iter=3, warm_start=True, learning_rate='constant', eta0=0.01)\n","model.fit(X_initial_train, y_initial_train)\n","\n","y_pred_initial = model.predict(X_initial_train)\n","initial_rmse = np.sqrt(mean_squared_error(y_initial_train, y_pred_initial))\n","print(f\"Initial RMSE after first 10,000 records: {initial_rmse:.2f}\")\n","\n","for i, (X_new_batch, y_new_batch) in enumerate(zip(new_data_chunks, new_target_chunks), start=1):\n","    model.partial_fit(X_new_batch, y_new_batch)\n","    y_pred = model.predict(X_initial_train)\n","    rmse = np.sqrt(mean_squared_error(y_initial_train, y_pred))\n","    print(f\"RMSE after adding {i * 100} new records: {rmse:.2f}\")\n","\n","print(\"Continuous learning with 100-record updates finished.\")\n"]}]}