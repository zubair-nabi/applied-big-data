{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1StdngpTC5hTG_hxgyd5NlOzS9BkMISbA","timestamp":1741229963518},{"file_id":"19BhUm_FMtKWCVOUF5SfyczNWx8d03MOm","timestamp":1741228506965}],"authorship_tag":"ABX9TyO8X5IW89iLBk/eHzYe7vRg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install mlflow"],"metadata":{"id":"s0KYHH-gZdLE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBzu7LSzQ9R3","executionInfo":{"status":"ok","timestamp":1741231744612,"user_tz":300,"elapsed":85894,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"9fad4f55-cf25-4e76-f850-b72d7b884a14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Root Mean Squared Error (RMSE): 19889.452833942414\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[31m2025/03/06 03:29:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","Registered model 'HousingPricePredictionPipeline' already exists. Creating a new version of this model...\n","Created version '4' of model 'HousingPricePredictionPipeline'.\n"]},{"output_type":"stream","name":"stdout","text":["runs:/f633a64a1d2b4a08b575f06226baa6a4/housing_price_pipeline\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import numpy as np\n","import mlflow\n","import mlflow.spark\n","\n","spark = SparkSession.builder.appName(\"Housing Price Prediction Pipeline\").getOrCreate()\n","\n","locations = ['Los Angeles, CA', 'San Francisco, CA', 'Austin, TX', 'Miami, FL',\n","             'New York, NY', 'Denver, CO', 'Chicago, IL', 'Seattle, WA',\n","             'Atlanta, GA', 'Boston, MA']\n","nearby_transport_options = ['Yes', 'No']\n","\n","data = []\n","for _ in range(10000):\n","    location = np.random.choice(locations)\n","    bedrooms = int(np.random.randint(1, 5))\n","    bathrooms = int(np.random.randint(1, 4))\n","    size_sqft = float(np.random.normal(loc=1500, scale=300))\n","    lot_size_sqft = float(np.random.normal(loc=5000, scale=1000))\n","    days_on_market = int(np.random.randint(10, 90))\n","    interest_rate = float(np.random.uniform(2.5, 5.0))\n","    median_income = float(np.random.normal(loc=80000, scale=15000))\n","    school_rating = int(np.random.randint(5, 10))\n","    walkability_score = int(np.random.randint(50, 100))\n","    nearby_transport = np.random.choice(nearby_transport_options)\n","    sale_price = (100000 +\n","                  bedrooms * 30000 +\n","                  bathrooms * 20000 +\n","                  size_sqft * 200 +\n","                  lot_size_sqft * 10 +\n","                  median_income * 0.5 +\n","                  float(np.random.normal(0, 20000)))\n","    data.append((str(location), bedrooms, bathrooms, size_sqft, lot_size_sqft,\n","                 days_on_market, interest_rate, median_income, school_rating,\n","                 walkability_score, str(nearby_transport), float(sale_price)))\n","\n","columns = ['Location', 'Bedrooms', 'Bathrooms', 'Size_SqFt', 'Lot_Size_SqFt',\n","           'Days_on_Market', 'Interest_Rate', 'Median_Income', 'School_Rating',\n","           'Walkability_Score', 'Nearby_Transport', 'Sale_Price']\n","\n","df = spark.createDataFrame(data, columns)\n","\n","indexer_location = StringIndexer(inputCol=\"Location\", outputCol=\"Location_Index\")\n","indexer_transport = StringIndexer(inputCol=\"Nearby_Transport\", outputCol=\"Transport_Index\")\n","\n","feature_columns = ['Location_Index', 'Bedrooms', 'Bathrooms', 'Size_SqFt',\n","                   'Lot_Size_SqFt', 'Days_on_Market', 'Interest_Rate',\n","                   'Median_Income', 'School_Rating', 'Walkability_Score', 'Transport_Index']\n","assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"Sale_Price\")\n","\n","pipeline = Pipeline(stages=[indexer_location, indexer_transport, assembler, scaler, lr])\n","train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n","pipeline_model = pipeline.fit(train_df)\n","\n","predictions = pipeline_model.transform(test_df)\n","evaluator = RegressionEvaluator(labelCol=\"Sale_Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = evaluator.evaluate(predictions)\n","print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n","\n","# Use MLflow to log and register the model\n","with mlflow.start_run() as run:\n","    mlflow.log_metric(\"rmse\", rmse)\n","    mlflow.spark.log_model(pipeline_model, \"housing_price_pipeline\")\n","    run_id = run.info.run_id\n","\n","    model_uri = f\"runs:/{run_id}/housing_price_pipeline\"\n","    print(model_uri)\n","    registered_model = mlflow.register_model(model_uri, \"HousingPricePredictionPipeline\")\n","\n","spark.stop()\n"]},{"cell_type":"code","source":["import subprocess\n","import threading\n","\n","def read_output(pipe):\n","    for line in iter(pipe.readline, ''):\n","        print(line, end='')\n","\n","mlflow_cmd = [\n","    \"mlflow\", \"models\", \"serve\",\n","    \"--model-uri\", \"runs:/f633a64a1d2b4a08b575f06226baa6a4/housing_price_pipeline\",\n","    \"--port\", \"5000\",\n","    \"--no-conda\"\n","]\n","\n","process = subprocess.Popen(\n","    mlflow_cmd,\n","    stdout=subprocess.PIPE,\n","    stderr=subprocess.PIPE,\n","    universal_newlines=True\n",")\n","\n","threading.Thread(target=read_output, args=(process.stdout,), daemon=True).start()\n","threading.Thread(target=read_output, args=(process.stderr,), daemon=True).start()\n","\n","print(\"MLflow model server started.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5x4FBrkaA_X","executionInfo":{"status":"ok","timestamp":1741232026379,"user_tz":300,"elapsed":9,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"fdfd3030-cc89-495b-d533-886da0b459d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MLflow model server started.\n"]}]},{"cell_type":"code","source":["import requests\n","import json\n","import time\n","\n","data = {\n","    \"dataframe_split\": {\n","        \"columns\": [\n","            \"Location_Index\", \"Bedrooms\", \"Bathrooms\", \"Size_SqFt\", \"Lot_Size_SqFt\",\n","            \"Days_on_Market\", \"Interest_Rate\", \"Median_Income\", \"School_Rating\",\n","            \"Walkability_Score\", \"Transport_Index\"\n","        ],\n","        \"data\": [\n","            [3.0, 3, 2, 1600, 5500, 30, 3.5, 75000, 8, 80, 1.0]\n","        ]\n","    }\n","}\n","\n","response = requests.post(\"http://127.0.0.1:5000/invocations\", json=data)\n","print(\"Predictions:\", response.json())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4Zr9tgsdlgC","executionInfo":{"status":"ok","timestamp":1741232140286,"user_tz":300,"elapsed":5871,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"e16c084e-2043-4bee-e69f-9f9cb3214c9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                                                                    \n","25/03/06 03:35:35 WARN StringIndexerModel: Input column Location does not exist during transformation. Skip StringIndexerModel for this column.\n","25/03/06 03:35:35 WARN StringIndexerModel: Input column Nearby_Transport does not exist during transformation. Skip StringIndexerModel for this column.\n","\n","[Stage 20:>                                                                             (0 + 1) / 1]\n","\n","Predictions: {'predictions': [643028.0507890107]}\n"]}]}]}