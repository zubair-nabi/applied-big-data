{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMub6TLSRCstU7DNQrsSAD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBzu7LSzQ9R3","executionInfo":{"status":"ok","timestamp":1741227951171,"user_tz":300,"elapsed":50358,"user":{"displayName":"Zubair Nabi","userId":"14783280215479013636"}},"outputId":"88ea0810-cecc-4c8e-ea81-d4d090f2f432"},"outputs":[{"output_type":"stream","name":"stdout","text":["Root Mean Squared Error (RMSE): 19981.213254848717\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import numpy as np\n","\n","spark = SparkSession.builder.appName(\"Housing Price Prediction Pipeline\").getOrCreate()\n","\n","locations = ['Los Angeles, CA', 'San Francisco, CA', 'Austin, TX', 'Miami, FL',\n","             'New York, NY', 'Denver, CO', 'Chicago, IL', 'Seattle, WA',\n","             'Atlanta, GA', 'Boston, MA']\n","nearby_transport_options = ['Yes', 'No']\n","\n","data = []\n","for _ in range(10000):\n","    location = np.random.choice(locations)\n","    bedrooms = int(np.random.randint(1, 5))\n","    bathrooms = int(np.random.randint(1, 4))\n","    size_sqft = float(np.random.normal(loc=1500, scale=300))\n","    lot_size_sqft = float(np.random.normal(loc=5000, scale=1000))\n","    days_on_market = int(np.random.randint(10, 90))\n","    interest_rate = float(np.random.uniform(2.5, 5.0))\n","    median_income = float(np.random.normal(loc=80000, scale=15000))\n","    school_rating = int(np.random.randint(5, 10))\n","    walkability_score = int(np.random.randint(50, 100))\n","    nearby_transport = np.random.choice(nearby_transport_options)\n","    sale_price = (100000 +\n","                  bedrooms * 30000 +\n","                  bathrooms * 20000 +\n","                  size_sqft * 200 +\n","                  lot_size_sqft * 10 +\n","                  median_income * 0.5 +\n","                  float(np.random.normal(0, 20000)))\n","    data.append((str(location), bedrooms, bathrooms, size_sqft, lot_size_sqft,\n","                 days_on_market, interest_rate, median_income, school_rating,\n","                 walkability_score, str(nearby_transport), float(sale_price)))\n","\n","columns = ['Location', 'Bedrooms', 'Bathrooms', 'Size_SqFt', 'Lot_Size_SqFt',\n","           'Days_on_Market', 'Interest_Rate', 'Median_Income', 'School_Rating',\n","           'Walkability_Score', 'Nearby_Transport', 'Sale_Price']\n","\n","df = spark.createDataFrame(data, columns)\n","\n","indexer_location = StringIndexer(inputCol=\"Location\", outputCol=\"Location_Index\")\n","indexer_transport = StringIndexer(inputCol=\"Nearby_Transport\", outputCol=\"Transport_Index\")\n","\n","feature_columns = ['Location_Index', 'Bedrooms', 'Bathrooms', 'Size_SqFt',\n","                   'Lot_Size_SqFt', 'Days_on_Market', 'Interest_Rate',\n","                   'Median_Income', 'School_Rating', 'Walkability_Score', 'Transport_Index']\n","assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"Sale_Price\")\n","\n","pipeline = Pipeline(stages=[indexer_location, indexer_transport, assembler, scaler, lr])\n","train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n","pipeline_model = pipeline.fit(train_df)\n","predictions = pipeline_model.transform(test_df)\n","evaluator = RegressionEvaluator(labelCol=\"Sale_Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = evaluator.evaluate(predictions)\n","print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n","\n","spark.stop()\n"]}]}